{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233be5c2-f224-4d8c-a53e-ecf525da9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
      "Found 5143 images belonging to 4 classes.\n",
      "Found 569 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n",
      "[INFO] Class indices: {'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,124</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m5,124\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,054,695</span> (15.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,054,695\u001b[0m (15.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,124</span> (20.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,124\u001b[0m (20.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - accuracy: 0.6961 - loss: 0.7753\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78910, saving model to C:\\Users\\sagni\\Downloads\\MRI Scan\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 471ms/step - accuracy: 0.6964 - loss: 0.7747 - val_accuracy: 0.7891 - val_loss: 0.6029 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.8599 - loss: 0.3875\n",
      "Epoch 2: val_accuracy improved from 0.78910 to 0.81019, saving model to C:\\Users\\sagni\\Downloads\\MRI Scan\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 424ms/step - accuracy: 0.8600 - loss: 0.3875 - val_accuracy: 0.8102 - val_loss: 0.5187 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.8821 - loss: 0.3346\n",
      "Epoch 3: val_accuracy improved from 0.81019 to 0.84007, saving model to C:\\Users\\sagni\\Downloads\\MRI Scan\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 392ms/step - accuracy: 0.8821 - loss: 0.3346 - val_accuracy: 0.8401 - val_loss: 0.4360 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8957 - loss: 0.2958\n",
      "Epoch 4: val_accuracy did not improve from 0.84007\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 401ms/step - accuracy: 0.8957 - loss: 0.2958 - val_accuracy: 0.8366 - val_loss: 0.4236 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9079 - loss: 0.2754\n",
      "Epoch 5: val_accuracy did not improve from 0.84007\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 401ms/step - accuracy: 0.9079 - loss: 0.2754 - val_accuracy: 0.8366 - val_loss: 0.4609 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.8972 - loss: 0.2700\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.84007 to 0.84183, saving model to C:\\Users\\sagni\\Downloads\\MRI Scan\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 387ms/step - accuracy: 0.8972 - loss: 0.2700 - val_accuracy: 0.8418 - val_loss: 0.4275 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.9102 - loss: 0.2627\n",
      "Epoch 7: val_accuracy improved from 0.84183 to 0.84710, saving model to C:\\Users\\sagni\\Downloads\\MRI Scan\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 413ms/step - accuracy: 0.9102 - loss: 0.2627 - val_accuracy: 0.8471 - val_loss: 0.4246 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9157 - loss: 0.2448\n",
      "Epoch 8: val_accuracy improved from 0.84710 to 0.85237, saving model to C:\\Users\\sagni\\Downloads\\MRI Scan\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 2s/step - accuracy: 0.9157 - loss: 0.2448 - val_accuracy: 0.8524 - val_loss: 0.3993 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9156 - loss: 0.2308\n",
      "Epoch 9: val_accuracy improved from 0.85237 to 0.85940, saving model to C:\\Users\\sagni\\Downloads\\MRI Scan\\model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 386ms/step - accuracy: 0.9156 - loss: 0.2309 - val_accuracy: 0.8594 - val_loss: 0.3860 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9231 - loss: 0.2294\n",
      "Epoch 10: val_accuracy did not improve from 0.85940\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 383ms/step - accuracy: 0.9231 - loss: 0.2294 - val_accuracy: 0.8594 - val_loss: 0.3940 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.9140 - loss: 0.2370\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.85940\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 378ms/step - accuracy: 0.9140 - loss: 0.2369 - val_accuracy: 0.8366 - val_loss: 0.4199 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.9205 - loss: 0.2267\n",
      "Epoch 12: val_accuracy did not improve from 0.85940\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 369ms/step - accuracy: 0.9205 - loss: 0.2267 - val_accuracy: 0.8471 - val_loss: 0.4093 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9210 - loss: 0.2286\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.85940\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 354ms/step - accuracy: 0.9210 - loss: 0.2286 - val_accuracy: 0.8366 - val_loss: 0.4384 - learning_rate: 2.5000e-04\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved model → C:\\Users\\sagni\\Downloads\\MRI Scan\\model.h5\n",
      "[INFO] Saved class_indices → C:\\Users\\sagni\\Downloads\\MRI Scan\\class_indices.pkl\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 232ms/step - accuracy: 0.8402 - loss: 0.3460\n",
      "[INFO] Test accuracy: 0.8886\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step\n",
      "[INFO] Saved metrics.json → C:\\Users\\sagni\\Downloads\\MRI Scan\\metrics.json\n",
      "[INFO] Saved run_config.yaml → C:\\Users\\sagni\\Downloads\\MRI Scan\\run_config.yaml\n",
      "\n",
      "[DONE] All artifacts saved to: C:\\Users\\sagni\\Downloads\\MRI Scan\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG (Windows raw strings)\n",
    "# -----------------------------\n",
    "TRAIN_DIR = r\"C:\\Users\\sagni\\Downloads\\MRI Scan\\archive\\Training\"\n",
    "TEST_DIR  = r\"C:\\Users\\sagni\\Downloads\\MRI Scan\\archive\\Testing\"\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\sagni\\Downloads\\MRI Scan\"\n",
    "MODEL_H5   = str(Path(OUTPUT_DIR) / \"model.h5\")\n",
    "CLASS_PKL  = str(Path(OUTPUT_DIR) / \"class_indices.pkl\")\n",
    "RUN_YAML   = str(Path(OUTPUT_DIR) / \"run_config.yaml\")\n",
    "METRICS_JSON = str(Path(OUTPUT_DIR) / \"metrics.json\")\n",
    "\n",
    "# Optional helpful extras (won't break your requirement)\n",
    "ACC_PNG  = str(Path(OUTPUT_DIR) / \"accuracy_loss.png\")\n",
    "CM_PNG   = str(Path(OUTPUT_DIR) / \"confusion_matrix.png\")\n",
    "CR_CSV   = str(Path(OUTPUT_DIR) / \"classification_report.csv\")\n",
    "CM_CSV   = str(Path(OUTPUT_DIR) / \"confusion_matrix.csv\")\n",
    "\n",
    "# Training params\n",
    "IMG_SIZE    = (256, 256)   # MRI works well with a bit larger res\n",
    "BATCH_SIZE  = 16\n",
    "EPOCHS      = 20\n",
    "VAL_SPLIT   = 0.1          # taken from Training for early-stopping/monitor\n",
    "SEED        = 42\n",
    "BASE_LR     = 1e-3\n",
    "AUGMENT     = True         # light aug helps generalization\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility\n",
    "# -----------------------------\n",
    "def set_seed(s=SEED):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "set_seed()\n",
    "\n",
    "# -----------------------------\n",
    "# Sanity checks\n",
    "# -----------------------------\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "if not Path(TRAIN_DIR).exists():\n",
    "    raise FileNotFoundError(f\"Training dir not found: {TRAIN_DIR}\")\n",
    "if not Path(TEST_DIR).exists():\n",
    "    raise FileNotFoundError(f\"Testing dir not found:  {TEST_DIR}\")\n",
    "\n",
    "# Determine class order from TRAIN_DIR subfolders\n",
    "classes = sorted([p.name for p in Path(TRAIN_DIR).iterdir() if p.is_dir()])\n",
    "if not classes:\n",
    "    raise RuntimeError(f\"No class subfolders found under: {TRAIN_DIR}\")\n",
    "print(\"[INFO] Classes:\", classes)\n",
    "\n",
    "# -----------------------------\n",
    "# Data generators\n",
    "# -----------------------------\n",
    "if AUGMENT:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=VAL_SPLIT,\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        brightness_range=(0.95, 1.05),\n",
    "        fill_mode=\"nearest\"\n",
    "    )\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=VAL_SPLIT\n",
    "    )\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_flow = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=classes,                  # explicit order\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    "    seed=SEED\n",
    ")\n",
    "val_flow = val_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=classes,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,                    # deterministic for metrics\n",
    "    subset=\"validation\",\n",
    "    seed=SEED\n",
    ")\n",
    "test_flow = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=classes,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False                     # IMPORTANT for CM/report\n",
    ")\n",
    "\n",
    "num_classes = len(classes)\n",
    "print(\"[INFO] Class indices:\", train_flow.class_indices)\n",
    "\n",
    "# -----------------------------\n",
    "# Model: EfficientNetB0\n",
    "# -----------------------------\n",
    "device = \"/GPU:0\" if tf.config.list_physical_devices(\"GPU\") else \"/CPU:0\"\n",
    "with tf.device(device):\n",
    "    base = EfficientNetB0(include_top=False, input_shape=(*IMG_SIZE, 3), weights=\"imagenet\")\n",
    "    base.trainable = False  # freeze for initial training\n",
    "\n",
    "    inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(BASE_LR),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------\n",
    "# Callbacks\n",
    "# -----------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=4, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint(MODEL_H5, monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Train\n",
    "# -----------------------------\n",
    "history = model.fit(\n",
    "    train_flow,\n",
    "    validation_data=val_flow,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save (best already saved by ModelCheckpoint; save current as well)\n",
    "model.save(MODEL_H5)\n",
    "print(f\"[INFO] Saved model → {MODEL_H5}\")\n",
    "\n",
    "# Save class map (PKL)\n",
    "with open(CLASS_PKL, \"wb\") as f:\n",
    "    pickle.dump(train_flow.class_indices, f)\n",
    "print(f\"[INFO] Saved class_indices → {CLASS_PKL}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate on TEST set\n",
    "# -----------------------------\n",
    "test_metrics = model.evaluate(test_flow, verbose=1)\n",
    "test_loss, test_acc = float(test_metrics[0]), float(test_metrics[1])\n",
    "print(f\"[INFO] Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Predict for confusion matrix & report\n",
    "probs_test = model.predict(test_flow, verbose=1)\n",
    "y_pred = np.argmax(probs_test, axis=1)\n",
    "y_true = test_flow.classes\n",
    "idx_to_class = {v: k for k, v in train_flow.class_indices.items()}\n",
    "labels_order = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "\n",
    "# Optional helpful artifacts (CSV + plots). Not required by you, but nice to have.\n",
    "cr = classification_report(y_true, y_pred, target_names=labels_order, output_dict=True, zero_division=0)\n",
    "pd.DataFrame(cr).to_csv(CR_CSV)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels_order))))\n",
    "pd.DataFrame(cm, index=labels_order, columns=labels_order).to_csv(CM_CSV)\n",
    "\n",
    "# Accuracy/Loss plot (optional)\n",
    "plt.figure(figsize=(10,8))\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "ax1.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "ax1.set_title(\"Accuracy\"); ax1.set_xlabel(\"Epoch\"); ax1.set_ylabel(\"Acc\"); ax1.grid(alpha=0.25); ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "ax2.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "ax2.set_title(\"Loss\"); ax2.set_xlabel(\"Epoch\"); ax2.set_ylabel(\"Loss\"); ax2.grid(alpha=0.25); ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ACC_PNG, dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Confusion matrix heatmap (optional)\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "cm_norm = np.nan_to_num(cm_norm)\n",
    "fig = plt.figure(figsize=(9,7))\n",
    "ax = plt.gca()\n",
    "im = ax.imshow(cm_norm, interpolation=\"nearest\", cmap=\"viridis\")\n",
    "plt.title(\"Confusion Matrix (Normalized)\")\n",
    "cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "cbar.ax.set_ylabel(\"Proportion\", rotation=90)\n",
    "ticks = np.arange(len(labels_order))\n",
    "plt.xticks(ticks, labels_order, rotation=45, ha=\"right\")\n",
    "plt.yticks(ticks, labels_order)\n",
    "thresh = cm_norm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    ax.text(j, i, f\"{cm[i,j]}\\n{cm_norm[i,j]*100:.1f}%\",\n",
    "            ha=\"center\", va=\"center\",\n",
    "            color=\"white\" if cm_norm[i, j] > thresh else \"black\",\n",
    "            fontsize=9)\n",
    "plt.ylabel(\"True label\"); plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout(); plt.savefig(CM_PNG, dpi=220); plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save metrics.json (training curves + test metrics)\n",
    "# -----------------------------\n",
    "metrics_payload = {\n",
    "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "    \"device\": device,\n",
    "    \"classes\": labels_order,\n",
    "    \"params\": {\n",
    "        \"img_size\": list(IMG_SIZE),\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs_requested\": EPOCHS,\n",
    "        \"val_split_from_training\": VAL_SPLIT,\n",
    "        \"base_lr\": BASE_LR,\n",
    "        \"augment\": AUGMENT\n",
    "    },\n",
    "    \"history\": {k: [float(v) for v in vals] for k, vals in history.history.items()},\n",
    "    \"final\": {\n",
    "        \"train_accuracy\": float(history.history[\"accuracy\"][-1]),\n",
    "        \"train_loss\": float(history.history[\"loss\"][-1]),\n",
    "        \"val_accuracy\": float(history.history[\"val_accuracy\"][-1]),\n",
    "        \"val_loss\": float(history.history[\"val_loss\"][-1]),\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"test_loss\": test_loss\n",
    "    }\n",
    "}\n",
    "with open(METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics_payload, f, indent=2)\n",
    "print(f\"[INFO] Saved metrics.json → {METRICS_JSON}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save run_config.yaml\n",
    "# -----------------------------\n",
    "run_cfg = {\n",
    "    \"run\": {\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"seed\": SEED,\n",
    "        \"device\": device\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"train_dir\": TRAIN_DIR,\n",
    "        \"test_dir\": TEST_DIR,\n",
    "        \"classes\": labels_order,\n",
    "        \"val_split\": VAL_SPLIT\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"architecture\": \"EfficientNetB0\",\n",
    "        \"transfer_learning\": True,\n",
    "        \"frozen_base\": True,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": BASE_LR,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"image_size\": list(IMG_SIZE),\n",
    "        \"num_classes\": num_classes\n",
    "    },\n",
    "    \"artifacts\": {\n",
    "        \"model_h5\": MODEL_H5,\n",
    "        \"class_indices_pkl\": CLASS_PKL,\n",
    "        \"metrics_json\": METRICS_JSON,\n",
    "        \"classification_report_csv\": CR_CSV,\n",
    "        \"confusion_matrix_csv\": CM_CSV,\n",
    "        \"accuracy_loss_png\": ACC_PNG,\n",
    "        \"confusion_matrix_png\": CM_PNG\n",
    "    }\n",
    "}\n",
    "with open(RUN_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(run_cfg, f, sort_keys=False, allow_unicode=True)\n",
    "print(f\"[INFO] Saved run_config.yaml → {RUN_YAML}\")\n",
    "\n",
    "print(\"\\n[DONE] All artifacts saved to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72f9e9-f06b-4260-824a-84a66d4121c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
